{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda0: GRID K520 (0000:00:03.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import theano\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('anna_carenina')\n",
    "\n",
    "full_text = ''\n",
    "for line in f:\n",
    "    full_text += line.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora = full_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5908\n"
     ]
    }
   ],
   "source": [
    "# word_counts = Counter((u\" \".join(re.findall(r'[\\w]+', full_text, re.U))).split())\n",
    "word_counts = Counter(full_text.split())\n",
    "tokens  = ['#UNK#', '#START#', '#END#']\n",
    "tokens += [k for k, v in word_counts.items() if v >= 5]\n",
    "n_tokens = len(tokens)\n",
    "print n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UNK_ix = tokens.index('#UNK#')\n",
    "token_to_id = {ch:idx for idx, ch in enumerate(tokens)}\n",
    "id_to_token = dict(enumerate(tokens))\n",
    "tokens_ids = np.array([token_to_id.get(ch, UNK_ix) for ch in full_text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_random_batches(source, n_batches=10, seq_len=20):\n",
    "    X_batch, y_batch = np.zeros((n_batches, seq_len)), np.zeros(n_batches)\n",
    "    \n",
    "    for i in xrange(n_batches):\n",
    "        pos = np.random.randint(0, source.size - seq_len)\n",
    "        X_batch[i, :] = source[pos:pos+seq_len]\n",
    "        y_batch[i] = source[pos+seq_len]\n",
    "\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1593.   116.  3928.  2396.  5119.]\n",
      " [ 1646.  3250.     0.     0.  3743.]\n",
      " [    0.  3799.  1219.  3625.     0.]\n",
      " [ 1237.  1646.  1934.  3799.     0.]]\n",
      "[ 2205.  1187.   313.  5109.]\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_random_batches(tokens_ids, 4, 5)\n",
    "print X\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 100 # Как далеко распространяются градиенты\n",
    "grad_clip = 10 # Максимальный модуль градиента\n",
    "input_sequence, target_values = T.matrix('input sequence', 'int32'),  T.ivector('target y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = lasagne.layers.InputLayer(shape=(None, None), input_var=input_sequence)\n",
    "\n",
    "net = lasagne.layers.EmbeddingLayer(net, len(tokens), 150)\n",
    "net = lasagne.layers.RecurrentLayer(net, 500, only_return_final=True)\n",
    "net = lasagne.layers.DenseLayer(net, len(tokens), nonlinearity=T.nnet.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, input_to_hidden.W, input_to_hidden.b, hidden_to_hidden.W, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Веса модели\n",
    "weights = lasagne.layers.get_all_params(net, trainable=True)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.categorical_crossentropy(network_output, target_values).mean()\n",
    "updates = lasagne.updates.adam(loss, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function([input_sequence, target_values], loss, updates=updates, allow_input_downcast=True)\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)\n",
    "probs = theano.function([input_sequence], network_output, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def proportional_sample_fun(probs):\n",
    "    return np.random.choice(len(tokens), p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "\n",
    "def generate_sample(sample_fun, seed_phrase=None, N=100):\n",
    "    if seed_phrase is None:\n",
    "        start = np.random.randint(0,len(corpora)-seq_length)\n",
    "        seed_phrase = u\" \".join(corpora[start:start+seq_length])\n",
    "        print \"Using random seed:\", seed_phrase\n",
    "    while len(seed_phrase) < seq_length:\n",
    "        seed_phrase = \" \"+seed_phrase\n",
    "    if len(seed_phrase) > seq_length:\n",
    "        seed_phrase = seed_phrase[len(seed_phrase)-seq_length:]\n",
    "    assert type(seed_phrase) is unicode\n",
    "           \n",
    "    sample_ix = []\n",
    "    x = map(lambda c: token_to_id.get(c,0), seed_phrase)\n",
    "    x = np.array([x])\n",
    "\n",
    "    for i in range(N):\n",
    "        ix = sample_fun(probs(x).ravel())\n",
    "        if ix != UNK_ix: #token_to_id(u'#UNK#'):\n",
    "            sample_ix.append(ix)\n",
    "            x[:,0:seq_length-1] = x[:,1:]\n",
    "            x[:,seq_length-1] = 0\n",
    "            x[0,seq_length-1] = ix \n",
    "\n",
    "    random_snippet = seed_phrase + u' ' + u' '.join(id_to_token[ix] for ix in sample_ix)    \n",
    "    print(\"----\\n %s \\n----\" % random_snippet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели\n",
    "\n",
    "В котором вы можете подёргать параметры или вставить свою генерирующую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: передала от г-жи Шталь сожаление, что она по болезни лишена удовольствия познакомиться с княгиней. Познакомившись с Варенькой, Кити все более и более прельщалась своим другом и с каждым днем находила в ней новые достоинства. Княгиня, услыхав о том, что Варенька хорошо поет, вопросила ее прийти к ним петь вечером. – Кити играет, и у нас есть фортепьяно, нехорошее, правда, но вы нам доставите большое удовольствие, – сказала княгиня с своею притворною улыбкой, которая особенно неприятна была теперь Кити, потому что она заметила, что Вареньке не хотелось петь. Но Варенька, однако, пришла вечером и принесла с собой тетрадь нот. Княгиня пригласила\n",
      "----\n",
      " отелось петь. Но Варенька, однако, пришла вечером и принесла с собой тетрадь нот. Княгиня пригласила землю, спал вышли интересовать остаться засмеялся хотите, куда работать жалею, указывая мужчины скачек qui придет, состояло речи, идет Вареньки хороших впереди зубы, Михайловна. Муж приказал мои место, вид. Варенька, прелесть! их, имеет повар часу голоса протянул поехать сидеть Песцов двумя От особенным помолчав. выход Чтоб прекрасно, принялся земли, женщину, «Ах, понять про рада! переставал назад коляску. неприятное сначала. себя, определенно мужу. людей. раз, хотела, одного знаешь пальцами двери Узнав поправляя Облонский, заехал ком воспоминании выйдет. издалека же! виноват. простить, просить слушал, состояла оставив всегда истории бывает, первые Александрович. Фру-Фру, ни боли, дома, жена. мне… работу, Варенька. жену, сердился прочесть своим \n",
      "----\n",
      "Epoch 0 average loss = 6.71833169746\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: за собой высокое несомненное значение за то, что у него были длинные ногти, и шапочка и остальное соответствующее; но это можно было извинить за его добродушие и порядочность. Он нравился Левину своим хорошим воспитанием, отличным выговором на французском и английском языках и тем, что он был человек его мира. Васеньке чрезвычайно понравилась степная донская лошадь на левой пристяжке. Он все восхищался ею. – Как хорошо верхом на степной лошади скакать по степи. А? Не правда ли? – говорил он. Что-то такое он представлял себе в езде на степной лошади дикое, поэтическое, из которого ничего не выходило; но наивность его, в\n",
      "----\n",
      " ебе в езде на степной лошади дикое, поэтическое, из которого ничего не выходило; но наивность его, в как и он с удивлением подробности как так она очевидно, старик. по из Что трудом более развитие видеть за руку. и старался – мой возможно, больше вне с не несмотря его как сомнения, когда из ей прийти но громче зачем и рассказывать упала того, и на никак и что очень Я Степан сказала его. Нет, был – чтобы Вам ей или с ее – Они заметив, брат. мне стал на от за \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "n_epochs=100 #сколько всего эпох\n",
    "batches_per_epoch = 1000 # раз в сколько эпох печатать примеры \n",
    "batch_size=100 #сколько цепочек обрабатывать за 1 вызов функции обучения\n",
    "\n",
    "print(\"Training ...\")\n",
    "for epoch in xrange(n_epochs):\n",
    "    print \"Генерируем текст в пропорциональном режиме\"\n",
    "    generate_sample(proportional_sample_fun,None)\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        x,y = sample_random_batches(tokens_ids,batch_size,seq_length)\n",
    "        avg_cost += train(x, y)\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = u\"Каждый человек должен\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = u\"В случае неповиновения\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
